'''
This program reads a result file generated by SqueezeNet for breast cancer detection and calculates the performance metrics.
Input: 
    - one text file containing the results generated by SqueezeNet for breast cancer detection (one crop of an image per line).
Output: 
    - the performance metrics an confusion matrix for each pair of thresholds.
    - the optimal ROC and Precision-Recall curves.
'''

import sys
import argparse
from parse import parse
from join_dataset_results import join_file_lines

''' Global definitions '''
valid_classes = {0: 'benign', 1: 'malignant'}
step = 0.01
step_decimals = 2    

def is_int(x):
    try:
        int(x)
        return True
    except ValueError:
        return False


def is_float(x):
    try:
        float(x)
        return True
    except ValueError:
        return False


def error_msg(pattern, fields):
    print(pattern.format(*fields))
    return 1


def exit_msg(pattern, fields):
    print(pattern.format(*fields))
    exit()


def compute_confusion_matrix(input_data, threshold_1, threshold_2):
    true_p = true_n = false_p = false_n = 0
    
    for (mammogram_id, gt_class, crop_list) in input_data:
        accum_prob = sum( class_probs[1] for (crop_id, class_probs) in crop_list if class_probs[1] >= threshold_1 )
        crop_count = sum( 1 for (crop_id, class_probs) in crop_list if class_probs[1] >= threshold_1 )
        mean_prob = (float(accum_prob) / crop_count) if crop_count > 0 else 0.0
        if mean_prob >= threshold_2:
            if gt_class == 1:
                true_p += 1
            else:
                false_p += 1
        else:
            if  gt_class == 0:
                true_n += 1
            else:
                false_n += 1
    
    confusion_matrix = (true_p, true_n, false_p, false_n)           
    return confusion_matrix


def precision_formula(confusion_matrix):
    (true_p, true_n, false_p, false_n) = confusion_matrix
    precision = (float(true_p) / (true_p + false_p)) if (true_p + false_p) > 0 else 0.0
    return precision

def recall_formula(confusion_matrix):
    (true_p, true_n, false_p, false_n) = confusion_matrix
    recall = (float(true_p) / (true_p + false_n)) if (true_p + false_n) > 0 else 0.0
    return recall
    
def accuracy_formula(confusion_matrix):
    (true_p, true_n, false_p, false_n) = confusion_matrix
    accuracy = (float(true_p + true_n) / (true_p + true_n + false_p + false_n)) if (true_p + true_n + false_p + false_n) > 0 else 0.0
    return accuracy

def sensitivity_formula(confusion_matrix):
    sensitivity = recall_formula(confusion_matrix)
    return sensitivity

def specificity_formula(confusion_matrix):
    (true_p, true_n, false_p, false_n) = confusion_matrix
    specificity = (float(true_n) / (true_n + false_p)) if (true_n + false_p) > 0 else 0.0
    return specificity

def fall_out_formula(confusion_matrix):
    fall_out = 1.0 - specificity_formula(confusion_matrix)
    return fall_out

def f_measure_formula(confusion_matrix):
    precision = precision_formula(confusion_matrix)
    recall = recall_formula(confusion_matrix)
    f_measure = (2.0 * precision * recall / (precision + recall)) if (precision + recall) > 0.0 else 0.0
    return f_measure


def calculate_metrics_and_curves(curves, input_data, threshold_1, threshold_2, outfile):
    confusion_matrix = compute_confusion_matrix(input_data, threshold_1, threshold_2)
    precision = precision_formula(confusion_matrix)  
    recall = recall_formula(confusion_matrix)
    accuracy = accuracy_formula(confusion_matrix)
    fall_out = fall_out_formula(confusion_matrix)
    sensitivity = sensitivity_formula(confusion_matrix)
    f_measure = f_measure_formula(confusion_matrix)
    metrics = confusion_matrix + (precision, recall, accuracy, fall_out, sensitivity, f_measure)
    outfile.write((('{:17.' + str(step_decimals) + 'f}')*2 + '{:17}'*4 + '{:17.6f}'*6 + '\n').format(threshold_1, threshold_2, *metrics))

    for (curve_points, abscissa_formula, ordinate_formula, abscissa_title, ordinate_title) in curves:
        abscissa = round(abscissa_formula(confusion_matrix), step_decimals)
        ordinate = ordinate_formula(confusion_matrix)
        (optimal_ordinate, t1, t2) = curve_points.get(abscissa, (-1.0, -1.0, -1.0))
        if ordinate > optimal_ordinate:
            curve_points[abscissa] = (ordinate, threshold_1, threshold_2)


def insert_extrapolation(curves, input_data, lower_bound=0.0, upper_bound=1.0):
    ordinate_lower = ordinate_upper = None
    curve_extrapolation = []
    for curve in curves:
        (curve_points, abscissa_formula, ordinate_formula, abscissa_title, ordinate_title) = curve
        insert_lower = (curve_points.get(lower_bound) == None)
        insert_upper = (curve_points.get(upper_bound) == None)
        if insert_lower or insert_upper:
            extrapolation = (insert_lower, insert_upper, ordinate_lower, ordinate_upper)
            curve_extrapolation.append((curve, extrapolation))
    if not curve_extrapolation:
        return

    threshold_1 = 0.0
    while threshold_1 < 1.0:
        threshold_2 = 0.0
        while threshold_2 < 1.0:
            confusion_matrix = compute_confusion_matrix(input_data, threshold_1, threshold_2)
            for i, (curve, extrapolation) in enumerate(curve_extrapolation):
                (curve_points, abscissa_formula, ordinate_formula, abscissa_title, ordinate_title) = curve
                (insert_lower, insert_upper, ordinate_lower, ordinate_upper) = extrapolation
                abscissa = round(abscissa_formula(confusion_matrix), step_decimals)
                ordinate = ordinate_formula(confusion_matrix)
                if insert_lower and (abscissa == lower_bound) and (not ordinate_lower or ordinate_lower[0] < ordinate):
                    ordinate_lower = (ordinate, threshold_1, threshold_2)
                if insert_upper and (abscissa == upper_bound) and (not ordinate_upper or ordinate_upper[0] < ordinate):
                    ordinate_upper = (ordinate, threshold_1, threshold_2)
                extrapolation = (insert_lower, insert_upper, ordinate_lower, ordinate_upper)
                curve_extrapolation[i] = (curve, extrapolation)
            threshold_2 = round(threshold_2 + step, step_decimals)
        threshold_1 = round(threshold_1 + step, step_decimals)



    for (curve, extrapolation) in curve_extrapolation:
        (curve_points, abscissa_formula, ordinate_formula, abscissa_title, ordinate_title) = curve
        (insert_lower, insert_upper, ordinate_lower, ordinate_upper) = extrapolation
        if insert_lower and ordinate_lower:
            curve_points[lower_bound] = ordinate_lower
            print('{} extrapolated to {:.6f} for {}({})\n'.format(ordinate_title, ordinate_lower[0], abscissa_title, lower_bound))
        if insert_upper and ordinate_upper:
            curve_points[upper_bound] = ordinate_upper
            print('{} extrapolated to {:.6f} for {}({})\n'.format(ordinate_title, ordinate_upper[0], abscissa_title, upper_bound))


def calculate_auc(curve, curve_description=''):
    auc = 0.0
    (previous_x, (previous_y, previous_t1, previous_t2)) = curve[0]
    for (x, (y, t1, t2)) in curve[1:]:
        dx = (x - previous_x)
        dy = (y - previous_y)
        auc += (dx * previous_y) + (dx * dy * 0.5)
        previous_x = x
        previous_y = y
    if curve_description:
        print('\nAUC of {} curve is {:.6f}\n'.format(curve_description, auc))
    return auc


def read_threshold_file(infile):
    if not infile:
        return []
    line_pattern = '{threshold_1} {threshold_2}'
    threshold_data = []
    linenum = errors = 0
    print('\nProcessing file \'{}\' ...'.format(infile.name))
    for (linenum, line) in enumerate(infile, start=1):
        if line[:1] == '#':
            continue
        thresholds = [ float(t) if is_float(t) else -1.0 for t in line.split()[:2] ]
        if len(thresholds) < 2:
            errors += error_msg('{}Error in line #{}: text does not match expected pattern: {}', (line, linenum, line_pattern))
            continue
        thresholds_invalid = sum( 1 for t in thresholds if not (0.0 <= t <= 1.0) )
        if thresholds_invalid > 0:
            errors += error_msg('{}Error in line #{}: thresholds must be in (0.0 ... 1.0)', (line, linenum))
            continue
        threshold_data.append(thresholds)
    print('\nRecord count:    {:7}\nError count:     {:7}\n'.format(linenum, errors))
    if not threshold_data:
        exit_msg('{} has no valid records!\n', [infile.name])
    return threshold_data


def read_input_file(infile, infile_name):
    line_pattern = '{mammogram_id}_Crop_{crop_id}.png,{gt_class},{class_probs}'
    input_data = []
    linenum = errors = 0
    previous_mammogram_id = previous_gt_class = None
    print('\nProcessing file \'{}\' ...'.format(infile_name))
    for (linenum, line) in enumerate(infile, start=1):
        if line[:1] == '#':
            continue
        fields = parse(line_pattern, line)
        if not fields:
            errors += error_msg('{}Error in line #{}: text does not match expected pattern: {}', (line, linenum, line_pattern))
            continue
        mammogram_id = fields['mammogram_id']
        crop = fields['crop_id']
        crop_id = int(crop) if is_int(crop) else crop
        gt = fields['gt_class']
        gt_class = int(gt) if is_int(gt) else gt
        if valid_classes.get(gt_class) == None:
            errors += error_msg('{}Error in line #{}: invalid gt_class: {}\nValid classes are: {}', (line, linenum, gt_class, valid_classes))
            continue
        class_probs = [ float(prob) if is_float(prob) else -1.0 for prob in fields['class_probs'].split(',') ]
        if len(class_probs) > len(valid_classes):
            errors += error_msg('{}Error in line #{}: too many class probabilities: {}\nValid classes are: {}', (line, linenum, class_probs, valid_classes))
            continue
        class_probs_invalid = sum( 1 for prob in class_probs if not (0.0 <= prob <= 1.0) )
        if class_probs_invalid > 0:
            errors += error_msg('{}Error in line #{}: class probabilities must be in (0.0 ... 1.0)', (line, linenum))
            continue
        total_prob = round(sum(class_probs), 6)
        if total_prob != 1.0:
            errors += error_msg('{}Error in line #{}: total probability is not equal to 1.0: {:.6f}\nList of class probabilities: {}', (line, linenum, total_prob, class_probs))
            continue
        if  mammogram_id != previous_mammogram_id:
            crop_list = []
            input_data.append((mammogram_id, gt_class, crop_list))
            previous_mammogram_id = mammogram_id
            previous_gt_class = gt_class
        elif previous_gt_class != gt_class:
            errors += error_msg('{}Error in line #{}: mammogram\'s gt_class is {} but this crop\'s gt_class is {}', (line, linenum, previous_gt_class, gt_class))
        else:
            crop_list.append((crop_id, class_probs))
    print('\nRecord count:    {:7}\nError count:     {:7}\nMammogram count: {:7}\n'.format(linenum, errors, len(input_data)))
    if not input_data:
        exit_msg('{} has no valid records!\n', [infile_name])
    return input_data


def get_infile(file_i, file_i1, file_i2):
    if file_i:
        if file_i1 or file_i2:
            exit_msg('Input file arguments -i, -i1, -i2 cannot be used simultaneously!\n', [])
        infile = list(file_i)
        infile_name = file_i.name
    elif file_i1 and file_i2:
        infile = join_file_lines(file_i1, file_i2, join_char=',')
        infile_name = file_i1.name
    elif file_i1 or file_i2:
        exit_msg('Input file arguments -i1 and -i2 should be used simultaneously!\n', [])
    else:
        exit_msg('No input file arguments -i, -i1, -i2 used!\n', [])
    return (infile, infile_name)


def set_step_decimals(value, default_value):
    global step, step_decimals
    step = value
    if not 0.0 < step <= 1.0:
        exit_msg('\nThreshold --step argument must be between 0.0 and 1.0 (default value: {})\n', [default_value])
    step_frac = str(step).split('.')[-1]
    step_decimals = len(step_frac) if step_frac != '0' else 0


def write_outfile_header(outfile):
    outfile.write('#')
    outfile_labels = ('Threshold', 'Threshold', 'True_P', 'True_N', 'False_P', 'False_N', 'Precision', 'Recall', 'Accuracy', 'Fall_Out', 'Sensitivity', 'F_Measure')
    for (i, label) in enumerate(outfile_labels, start=1): 
        outfile.write('{:>16} '.format(str(i) + '_' + label))
    outfile.write('\n')
    outfile.write(('# ' + ('=' * 15 + '  ') * len(outfile_labels) + '\n'))


def write_curve_output(curve_output):
    (curve, curve_title, curve_outfile) = curve_output
    (curve_points, abscissa_formula, ordinate_formula, abscissa_title, ordinate_title) = curve
    outfile_labels = ('1_Threshold','2_Threshold', '3_' + abscissa_title, '4_' + ordinate_title)
    curve_outfile.write(('#' + '{:>16} ' * len(outfile_labels) + '\n').format(*outfile_labels))
    curve_outfile.write(('# ' + ('=' * 15 + '  ') * len(outfile_labels) + '\n'))
    curve_point_list = sorted(curve_points.items())
    for (key, values) in curve_point_list:
        curve_outfile.write(('{2:17.' + str(step_decimals) + 'f}{3:17.' + str(step_decimals) + 'f}{0:17.6f}{1:17.6f}\n').format(key, *values))
    auc = calculate_auc(curve_point_list, curve_title)
    finish_outfile(curve_outfile, curve_title + ' curve data')


def finish_outfile(outfile, file_description=''):
    if not outfile in (sys.stdout, sys.stderr):
        if file_description:
            print('Please find {} in file: \'{}\'\n'.format(file_description, outfile.name))
        outfile.close()


def read_args():
    parser = argparse.ArgumentParser(description='This program reads a result file generated by SqueezeNet for breast cancer detection '
        'and calculates the performance metrics.', formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('-i', '--infile', help='input file generated by SqueezeNet (i1+i2)', nargs='?', type=argparse.FileType('r'), default = None)
    parser.add_argument('-i1', '--infile1', help='input dataset file generated by SqueezeNet', nargs='?', type=argparse.FileType('r'), default = None)
    parser.add_argument('-i2', '--infile2', help='input probabilities file generated by SqueezeNet', nargs='?', type=argparse.FileType('r'), default = None)
    parser.add_argument('-tr', '--trocfile', help='threshold references for ROC curve (input file)', nargs='?', type=argparse.FileType('r'), default = None)
    parser.add_argument('-tp', '--tprfile', help='threshold references for Precision-Recall curve (input file)', nargs='?', type=argparse.FileType('r'), default = None)
    parser.add_argument('-o', '--outfile', help='performance metrics output file', nargs='?', type=argparse.FileType('w'), default=sys.stdout)
    parser.add_argument('-r', '--rocfile', help='ROC curve output file', nargs='?', type=argparse.FileType('w'), default=sys.stdout)
    parser.add_argument('-p', '--prfile', help='Precision-Recall curve output file', nargs='?', type=argparse.FileType('w'), default=sys.stdout)
    parser.add_argument('-s', '--step', help='step increment for thresholds', type=float, default=0.01)
    args = parser.parse_args()
    return (args, parser)

    
if __name__ == "__main__":
    (args, parser) = read_args()
    (infile, infile_name) = get_infile(args.infile, args.infile1, args.infile2)
    squeezenet_data = read_input_file(sorted(infile), infile_name)
    troc_data = read_threshold_file(args.trocfile)
    tpr_data  = read_threshold_file(args.tprfile)
    roc_curve = ( {1.00: (1.00, 0.00, 0.00)}, fall_out_formula, sensitivity_formula, 'Fall_Out', 'Sensitivity' )
    pr_curve  = ( {0.00: (1.00, 0.00, 1.00)}, recall_formula,   precision_formula,   'Recall',   'Precision'   )
    set_step_decimals(args.step, parser.get_default('step'))

    if args.trocfile:
        write_outfile_header(args.outfile)
        for (threshold_1, threshold_2) in troc_data:
            calculate_metrics_and_curves([roc_curve], squeezenet_data, threshold_1, threshold_2, args.outfile)

    if args.tprfile:
        write_outfile_header(args.outfile)
        for (threshold_1, threshold_2) in tpr_data:
            calculate_metrics_and_curves([pr_curve],  squeezenet_data, threshold_1, threshold_2, args.outfile)

    if not args.trocfile and not args.tprfile:
        write_outfile_header(args.outfile)
        threshold_1 = 0.0
        while threshold_1 < 1.0:
            threshold_2 = 0.0
            while threshold_2 < 1.0:
                calculate_metrics_and_curves([roc_curve, pr_curve], squeezenet_data, threshold_1, threshold_2, args.outfile)
                threshold_2 = round(threshold_2 + step, step_decimals)
            threshold_1 = round(threshold_1 + step, step_decimals)

    finish_outfile(args.outfile, 'all confusion matrices and performance indexes')

    insert_extrapolation([roc_curve, pr_curve], squeezenet_data, lower_bound=0.0, upper_bound=1.0)

    for curve_output in ((roc_curve, 'ROC', args.rocfile), (pr_curve, 'Precision-Recall', args.prfile)):
        write_curve_output(curve_output)
